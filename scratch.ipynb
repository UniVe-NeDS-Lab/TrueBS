{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy\n",
    "import networkx as nx\n",
    "from numba import cuda\n",
    "import warnings\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 1 1 0 0]]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _add_node(i : int, source : np.ndarray, temp : np.ndarray, subgraph : np.ndarray):\n",
    "    '''\n",
    "    Iteratively extract induced subgraph containing 'i' from source in subgraph. temp is used as a temporary location.\n",
    "    O(n) time complexity\n",
    "    O(2*s) space complexity\n",
    "    '''\n",
    "    # Copy i-th row in the temp matrix\n",
    "    temp[i,:] = source[i, :]\n",
    "    # Self-and to remove other edges\n",
    "    row =  np.bitwise_and(temp[:,i], temp[i,:].T)\n",
    "    # # Copy relevant row to target graph\n",
    "    subgraph[:,i] = row\n",
    "    subgraph[i,:] = row.T \n",
    "    #subgraph[:,:] = np.bitwise_and(temp, temp.T)\n",
    "\n",
    "def induced_subgaph(graph, nodes):\n",
    "    iab_g = np.zeros_like(graph)\n",
    "    temp_g =  np.zeros_like(graph)\n",
    "    for n in nodes:\n",
    "        _add_node(n, graph, temp_g, iab_g)\n",
    "    return iab_g\n",
    "\n",
    "\n",
    "#Generate random graph\n",
    "g = nx.gnp_random_graph(5, 0.4)\n",
    "#Convert to np adjmat\n",
    "adjmat = nx.to_numpy_matrix(g).astype(np.uint32)\n",
    "#Extract subgraph with custom method\n",
    "subg_np = induced_subgaph(adjmat, [1,2,3,4])\n",
    "print(subg_np)\n",
    "print(nx.Graph(subg_np).edges() == nx.subgraph(g, [1,2,3,4]).edges())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gabriele.gemmi/.virtualenvs/truenets/lib/python3.8/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 5 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n",
      "/home/gabriele.gemmi/.virtualenvs/truenets/lib/python3.8/site-packages/numba/cuda/dispatcher.py:488: NumbaPerformanceWarning: Grid size 5 will likely result in GPU under-utilization due to low occupancy.\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-1.41421356e+00,  0.00000000e+00,  0.00000000e+00,  7.54604712e-17,\n",
       "         1.41421356e+00]),\n",
       " array([[ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00],\n",
       "        [-5.00000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "          7.07106781e-01, -5.00000000e-01],\n",
       "        [-5.00000000e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "         -7.07106781e-01, -5.00000000e-01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00, -1.00000000e+00,\n",
       "          0.00000000e+00,  0.00000000e+00],\n",
       "        [ 7.07106781e-01,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.11022302e-16, -7.07106781e-01]]))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def cu_add_node(i : int, source, temp, subgraph):\n",
    "    copy_row[source.shape[0], 1](i, source, temp)\n",
    "    bitwise_rowcol[source.shape[0], 1](i, temp, subgraph)\n",
    "\n",
    "@cuda.jit()\n",
    "def copy_row(i, source, dest):\n",
    "    j = cuda.grid(1)\n",
    "    if j<source.shape[0]:\n",
    "        dest[i,j] = source[i,j]\n",
    "\n",
    "@cuda.jit()\n",
    "def bitwise_rowcol(i, source, dest):\n",
    "    j = cuda.grid(1)\n",
    "    if j<source.shape[0]:\n",
    "        dest[i,j] = dest[j, i] = source[i,j] & source[j,i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def induced_subgraph(graph, nodes):\n",
    "    c_graph = cuda.to_device(graph)\n",
    "    c_subgraph = cuda.to_device(np.zeros_like(adjmat))\n",
    "    c_temp = cuda.to_device(np.zeros_like(adjmat))\n",
    "    for n in nodes:\n",
    "        cu_add_node(n, c_graph, c_temp, c_subgraph)\n",
    "    return c_subgraph\n",
    "\n",
    "subg = induced_subgraph(adjmat, [1,2,3,4])\n",
    "\n",
    "cupy.linalg.eigh(cupy.asarray(subg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi matrix version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1 -1  0  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0  0  0]\n",
      " [ 0  0  1 -1  0  0  0  0]\n",
      " [ 0  0 -1  1  0  0  0  0]\n",
      " [ 0  0  0  0  1 -1  0  0]\n",
      " [ 0  0  0  0 -1  1  0  0]\n",
      " [ 0  0  0  0  0  0  1 -1]\n",
      " [ 0  0  0  0  0  0 -1  1]]\n",
      "[[ 1 -1  0  0  0  0  0  0]\n",
      " [-1  2 -1  0  0  0  0  0]\n",
      " [ 0 -1  2 -1  0  0  0  0]\n",
      " [ 0  0 -1  2 -1  0  0  0]\n",
      " [ 0  0  0 -1  2 -1  0  0]\n",
      " [ 0  0  0  0 -1  2 -1  0]\n",
      " [ 0  0  0  0  0 -1  2 -1]\n",
      " [ 0  0  0  0  0  0 -1  1]]\n",
      "Eigenval of m1\n",
      "[2.22044605e-16 2.22044605e-16 2.22044605e-16 2.22044605e-16\n",
      " 2.00000000e+00 2.00000000e+00 2.00000000e+00 2.00000000e+00]\n",
      "Eigenval of m2\n",
      "[-1.34744607e-16  1.52240935e-01  5.85786438e-01  1.23463314e+00\n",
      "  2.00000000e+00  2.76536686e+00  3.41421356e+00  3.84775907e+00]\n",
      "[[[ 1. -1.  0.  0.  0.  0.  0.  0.]\n",
      "  [-1.  1.  0.  0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  1. -1.  0.  0.  0.  0.]\n",
      "  [ 0.  0. -1.  1.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  1. -1.  0.  0.]\n",
      "  [ 0.  0.  0.  0. -1.  1.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.  0.  1. -1.]\n",
      "  [ 0.  0.  0.  0.  0.  0. -1.  1.]]\n",
      "\n",
      " [[ 1. -1.  0.  0.  0.  0.  0.  0.]\n",
      "  [-1.  2. -1.  0.  0.  0.  0.  0.]\n",
      "  [ 0. -1.  2. -1.  0.  0.  0.  0.]\n",
      "  [ 0.  0. -1.  2. -1.  0.  0.  0.]\n",
      "  [ 0.  0.  0. -1.  2. -1.  0.  0.]\n",
      "  [ 0.  0.  0.  0. -1.  2. -1.  0.]\n",
      "  [ 0.  0.  0.  0.  0. -1.  2. -1.]\n",
      "  [ 0.  0.  0.  0.  0.  0. -1.  1.]]]\n",
      "Combined\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   2.00000000e+00  2.00000000e+00  2.00000000e+00  2.00000000e+00]\n",
      " [-2.10966514e-17  1.52240935e-01  5.85786438e-01  1.23463314e+00\n",
      "   2.00000000e+00  2.76536686e+00  3.41421356e+00  3.84775907e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<class 'networkx.utils.decorators.argmap'> compilation 16:4: FutureWarning: laplacian_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "g = nx.Graph()\n",
    "g.add_edge(1,2)\n",
    "g.add_edge(3,4)\n",
    "g.add_edge(5,6)\n",
    "g.add_edge(7,8)\n",
    "g2 = nx.Graph()\n",
    "g2.add_edge(1,2)\n",
    "g2.add_edge(2,3)\n",
    "g2.add_edge(3,4)\n",
    "g2.add_edge(4,5)\n",
    "g2.add_edge(5,6)\n",
    "g2.add_edge(6,7)\n",
    "g2.add_edge(7,8)\n",
    "#Convert to np adjmat\n",
    "adjmat = nx.to_numpy_matrix(g).astype(np.uint32)\n",
    "adjmat2 = nx.to_numpy_matrix(g2).astype(np.uint32)\n",
    "#get laplacian matrix\n",
    "\n",
    "l1 = nx.laplacian_matrix(g).toarray()\n",
    "l2 = nx.laplacian_matrix(g2).toarray()\n",
    "print(l1)\n",
    "print(l2)\n",
    "print(\"Eigenval of m1\")\n",
    "print(cupy.linalg.eigvalsh(cupy.asarray(l1)))\n",
    "print(\"Eigenval of m2\")\n",
    "print(cupy.linalg.eigvalsh(cupy.asarray(l2)))\n",
    "m = np.zeros(shape=(2, adjmat.shape[0], adjmat.shape[1]))\n",
    "m[0] = l1\n",
    "m[1] = l2\n",
    "\n",
    "print(m)\n",
    "\n",
    "print(\"Combined\")\n",
    "print(cupy.linalg.eigvalsh(cupy.asarray([l1,l2])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph = nx.gnp_random_graph(n=5, p=1)\n",
    "graph = nx.gnp_random_graph(555, 0.4)\n",
    "adjmat = nx.to_numpy_matrix(graph).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cu_add_node(i : int, source, temp, subgraph):\n",
    "#     copy_row[source.shape[0], 1](i, source, temp)\n",
    "#     bitwise_rowcol[source.shape[0], 1](i, temp, subgraph)\n",
    "\n",
    "\n",
    "\n",
    "@cuda.jit()\n",
    "def copy_row(source, dest):\n",
    "    i,j = cuda.grid(2)\n",
    "    if j<source.shape[0] and i<source.shape[0]:\n",
    "        dest[i,i,j] = source[i,j]\n",
    "\n",
    "@cuda.jit()\n",
    "def bitwise_rowcol(source, dest):\n",
    "    i,j = cuda.grid(2)\n",
    "    if j<source.shape[0] and i<source.shape[0]:\n",
    "        dest[i,i,j] = dest[i, j, i] = source[i, i, j] & source[i, j, i] \n",
    "\n",
    "def cu_add_all_node(source, temp, subgraph):\n",
    "    copy_row[source.shape, (1,1)](source, temp)\n",
    "    bitwise_rowcol[source.shape, (1,1)](temp, subgraph)\n",
    "\n",
    "def cu_connectivity(subgraph, laplacian):\n",
    "    cu_laplacian[subgraph.shape, (1,1)](subgraph, laplacian)\n",
    "    eigv = cupy.linalg.eigvalsh(cupy.asarray(laplacian))\n",
    "    cc = np.zeros(shape=subgraph.shape[0])\n",
    "    print(subgraph.shape)\n",
    "    for i in range(subgraph.shape[0]):\n",
    "        for j in range(subgraph.shape[1]):\n",
    "            if eigv[i,j] > 1e-10:\n",
    "                cc[i] = j\n",
    "                break\n",
    "    print(eigv)\n",
    "    return cc\n",
    "        \n",
    "    \n",
    "\n",
    "@cuda.jit()\n",
    "def cu_laplacian(graph, lapl):\n",
    "    i,j = cuda.grid(2) #i is the graph index, j is the row index\n",
    "    if j<graph.shape[0] and i<graph.shape[0]:\n",
    "        d = 0\n",
    "        for k in range(graph.shape[0]): #iterate on the row\n",
    "            d+=graph[i, j, k]\n",
    "            lapl[i,j,k] = -1*graph[i,j,k] #set the negative values\n",
    "        lapl[i, j, j] = d  #Set the diagonal equal to the degree\n",
    "\n",
    "\n",
    "\n",
    "@cuda.jit()\n",
    "def copy_mat(m_i, mat1, mat2):\n",
    "    i,j = cuda.grid(2)\n",
    "    if j<mat1.shape[1] and i<mat1.shape[2]:\n",
    "        for k in range(mat1.shape[0]):\n",
    "            if k != m_i:\n",
    "                mat1[k,i,j] = mat1[m_i, i, j]\n",
    "                mat2[k,i,j] = mat2[m_i, i, j]\n",
    "\n",
    "\n",
    "\n",
    "def test(graph):\n",
    "    assert(graph.shape[0] == graph.shape[1])\n",
    "    n = graph.shape[0]\n",
    "    c_graph = cuda.to_device(graph)\n",
    "    c_subgraph = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.uint8))\n",
    "    c_temp = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.uint8))\n",
    "    c_lapl = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.int32))\n",
    "\n",
    "    \n",
    "    cu_add_all_node(c_graph, c_temp, c_subgraph)\n",
    "    copy_mat[graph.shape, (1,1)](i, c_temp, c_subgraph)\n",
    "    eig = cu_connectivity(c_subgraph, c_lapl)\n",
    "    \n",
    "#test(adjmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = adjmat.shape[0]\n",
    "c_graph = cuda.to_device(adjmat)\n",
    "c_subgraph = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.uint8))\n",
    "c_temp = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.uint8))\n",
    "c_lapl = cuda.to_device(np.zeros(shape=(n,n,n), dtype=np.int32))\n",
    "\n",
    "\n",
    "cu_add_all_node(c_graph, c_temp, c_subgraph)\n",
    "copy_mat[c_graph.shape, (1,1)](0, c_temp, c_subgraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 447 µs, sys: 15 µs, total: 462 µs\n",
      "Wall time: 411 µs\n"
     ]
    }
   ],
   "source": [
    "%time cu_laplacian[c_subgraph.shape, (1,1)](c_subgraph, c_lapl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 101 µs, sys: 3 µs, total: 104 µs\n",
      "Wall time: 108 µs\n"
     ]
    }
   ],
   "source": [
    "%time culap = cupy.asarray(c_lapl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 681 ms, sys: 3.78 ms, total: 685 ms\n",
      "Wall time: 684 ms\n"
     ]
    }
   ],
   "source": [
    "%time eigv = cupy.linalg.eigvalsh(culap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('truenets')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fea6613b8a94cfc7e50b2b8cea2888dcdf80e0f2c84ccc12d1853c6df6dc5cdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
